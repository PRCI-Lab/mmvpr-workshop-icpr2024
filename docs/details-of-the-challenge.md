The Multi-Modal Visual Pattern Recognition Workshop will feature three challenge tracks. The datasets for the tracks involve modalities including RGB, infrared thermal, depth, and event. The details of each track are as follows:   

**Track 1: Multi-Modal Tracking**     
This track aims to address the technical challenges associated with tracking objects in multi-modal data. The dataset for this task comprises 500 multi-modal videos, with 400 allocated for training purposes and the remaining 100 for testing.  

**Track 2: Multi-Modal Detection**    
The goal of this track is to explore techniques for detecting objects of interest in multi-modal data streams. The dataset for this task comprises 5000 multi-modal images in total, with 4000 images allocated for training and the remaining 1000 images for testing.  

**Track 3: Multi-Modal Action Recognition**    
This track focuses on recognizing human actions from multi-modal data sources. The dataset for this track contains 2500 multi-modal videos (2000 for training and 500 for test) spanning across 20 action classes.   

**_Note: The Top-3 teams in each track are required to submit a workshop paper describing their respective solutions. This workshop sets awards for the Top-3 of each track, 2 best research paper awards and 2 Best solution paper awards._**

